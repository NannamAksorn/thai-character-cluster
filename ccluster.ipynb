{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thai Character Cluster based on Dr. Virach Sornlertlamvanich "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = match begining of the line\n",
    "# q = optional\n",
    "# Thai consonants พยัญชนะต้น\n",
    "consonant = '[กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรลวศษสหฬอฮ]'\n",
    "consonantq = '[กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรลวศษสหฬอฮ]?'\n",
    "tconsonant = '^[กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรลวศษสหฬอฮ]'\n",
    "\n",
    "# Final consonant (speller) ตัวสะกด\n",
    "fconsonant = '[กขคฆงจชซญฎฏฐฑฒณดตถทธนบปพฟภมยรลวศษสฬอ]'\n",
    "tfconsonant = '^[กขคฆงจชซญฎฏฐฑฒณดตถทธนบปพฟภมยรลวศษสฬอ]'\n",
    "\n",
    "# Mixed cluster consonant พยัญชนะควบกล้ำทั้งหมด\n",
    "consonantc = '[กขคจฉซตถทบปผพฟศส]'\n",
    "tconsonantc = '^[กขคจฉซตถทบปผพฟศส]'\n",
    "\n",
    "# Cluster consonant with lo พยัญชนะควบ \"ล\"\n",
    "consonantl = '[กขคฉถบปผพฟ]'\n",
    "tconsonantl = '^[กขคฉถบปผพฟ]'\n",
    "\n",
    "# Cluster consonant with wo พยัญชนะควบ \"ว\"\n",
    "consonantw = '[กขค]'\n",
    "tconsonantw = '^[กขค]'\n",
    "\n",
    "# Cluster consonant with ho พยัญชนะ \"ห\" นำ\n",
    "consonanth = '[งญนมยรลว]'\n",
    "\n",
    "# Final character in mae kor kar กก, กด, กบ, กง, กน, กม, + กอ\n",
    "fkconsonant = '[กดบงนมอ]'\n",
    "\n",
    "# Thai vowel character\n",
    "vowel = '[ะาิีึืุูโเแัำไใฤฦ]'\n",
    "vowelq = '[ะาิีึืุูโเแัำไใฤฦ]?'\n",
    "\n",
    "# Thai Front vowel\n",
    "fvowel = '[เแไใโ]'\n",
    "\n",
    "# Thai tonal mark\n",
    "tone = \"[ ่ ้ ๋ ๊ ]\".replace(\" \", \"\")\n",
    "toneq = '[ ่่ ้ ๋ ๊ ]?'. replace(\" \", \"\")\n",
    "\n",
    "# Thai number\n",
    "number = '[๐๑๒๓๔๕๖๗๘๙]'\n",
    "\n",
    "# Thai special character\n",
    "special = '[็์ฯๆาฺํ()!?:;,.]'\n",
    "\n",
    "# Character that must follow a character\n",
    "strongbondchar = '[ะัาำิีึืฺุู็่้๊๋์]'\n",
    "nstrongbondchar = '[^ะัาำิีึืฺุู็่้๊๋์]'\n",
    "\n",
    "# Character that never used in start position (of word)\n",
    "nonstartchar = '[ะัาำิีึืฺุูิี้่็๋๊ํ]'\n",
    "startchar = '[^ะัาำิีึืฺุูิี้่็๋๊ํ]'\n",
    "\n",
    "# Character that never used in end position (of word)\n",
    "nonendchar = '[เแโใไั]'\n",
    "\n",
    "# Character that never used in the second position (of word)\n",
    "nonsecondchar = '[ๆ์]'\n",
    "\n",
    "# English Alphabet\n",
    "alphabet = '[A-Za-z]'\n",
    "\n",
    "# Number\n",
    "number = '[0-9]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - Default Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rule d1 ; ฯลฯ\n",
    "rule_d1 = r'(ฯลฯ)'\n",
    "\n",
    "# Rule d2 ; Alphabet\n",
    "rule_d2 = r'({}+)'.format(alphabet)\n",
    "\n",
    "# Rule d3 ; Number\n",
    "rule_d3 = r'({}+)'.format(number)\n",
    "\n",
    "# Rule d4 ; Attach ร์, ดิ์, ตร์, ทธิ์, ถุ์ to the existing previous unit\n",
    "rule_d4 = r'({}{}{}์)'.format(consonant, consonantq, vowelq)\n",
    "\n",
    "# Rule d5 ; Attach non-starting char to the existing previous unit\n",
    "rule_d5 = r'({})'.format(nonstartchar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - Level 0 very risky rule, apply to all types of cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rule l0.1 ใคร, ใกล้ ???? สา|เกล้|น|แก้ว, โคล้|อมวง X next must be fvowel\n",
    "rule_l0_1 = r'([เแไใโ]{}[รลว]{}){}'.format(consonantc,toneq,fvowel)\n",
    "\n",
    "# Rule l0.2 ; ไหน, ไหล่ X Edited\n",
    "rule_l0_2 = r'([เแไใโ]ห{}{}){}'.format(consonanth, toneq, startchar)\n",
    "\n",
    "# Rule l0.3 ; ครัว, ครั้ง ???? สิ|บวัน\n",
    "rule_l0_3 = r'({}[รลว]ั{}{})'.format(consonantc,toneq,fconsonant)\n",
    "\n",
    "# Rule l0.4 ; หนัง, หยั่ง\n",
    "rule_l0_4 = r'(ห{}ั{}{})'.format(consonanth, toneq,fconsonant)\n",
    "\n",
    "# Rule l0.5 ; คลำ, ประ, ??? แบ|บระ|บบ, แบ|บระ|ดับ\n",
    "rule_l0_5 = r'({}[รลว]{}[ะำ])'.format(consonantc,toneq)\n",
    "\n",
    "# Rule l0.6 ; หนำ, หวะ\n",
    "rule_l0_6 = r'(ห{}{}[ะำ])'.format(consonanth, toneq)\n",
    "\n",
    "# Rule l0.7 ; เสร็จ\n",
    "rule_l0_7 = r'([เแ]{}[รลว]็{})'.format(consonantc,fconsonant)\n",
    "\n",
    "# Rule l0.8 ; เหม็น\n",
    "rule_l0_8 = r'([เแ]ห{}็{})'.format(consonanth,fconsonant)\n",
    "\n",
    "# Rule l0.9 ; แคระ, โคร่ะ ???? แประ|ยะ\n",
    "rule_l0_9 = r'([เแโ]{}[รลว]{}ะ)'.format(consonantc, toneq)\n",
    "\n",
    "# Rule l0.10 ; โหละ โหล่ะ\n",
    "rule_l0_10 = r'([เแโ]ห{}{}ะ)'.format(consonanth, toneq)\n",
    "\n",
    "# Rule l0.11 ; เพราะ, เพร๋าะ\n",
    "rule_l0_11 = r'(เ{}[รลว]{}าะ)'.format(consonantc, toneq)\n",
    "\n",
    "# Rule l0.12 ; เหวาะ, เหร๊าะ\n",
    "rule_l0_12 = r'(เห{}{}าะ)'.format(consonanth, toneq)\n",
    "\n",
    "# Rule l0.13 ; เคว้า, เขย่า ??? เทลา|ด\n",
    "rule_l0_13 = r'(เ{}[รลว]{}า)'.format(consonantc, toneq)\n",
    "\n",
    "# Rule l0.14 ; เหว่า\n",
    "rule_l0_14 = r'(เห{}{}า)'.format(consonanth, toneq)\n",
    "\n",
    "# Rule l0.15 ; เกรอะ\n",
    "rule_l0_15 = r'(เ{}[รลว]{}อะ)'.format(consonantc, toneq)\n",
    "\n",
    "# Rule l0.16 ; เหล้อะ\n",
    "rule_l0_16 = r'(เห{}{}อะ)'.format(consonanth, toneq)\n",
    "\n",
    "# Rule l0.17 ; เคล๋ ????\n",
    "rule_l0_17 = r'(เ{}[รลว]{})'.format(consonantc, toneq)\n",
    "\n",
    "# Rule l0.18 ; เหล๋ ???\n",
    "rule_l0_18 = r'(เห{}{})'.format(consonanth, toneq)\n",
    "\n",
    "# Rule l0.19 ; เคลียะ\n",
    "rule_l0_19 = r'(เ{}[รลว]ี{}ยะ)'.format(consonantc, toneq)\n",
    "\n",
    "# Rule l0.20 ; เหรียะ\n",
    "rule_l0_20 = r'(เห{}ี{}ยะ)'.format(consonanth, toneq)\n",
    "\n",
    "# Rule l0.21 ; เครือะ\n",
    "rule_l0_21 = r'(เ{}[รลว]ื{}อะ)'.format(consonantc, toneq)\n",
    "\n",
    "# Rule l0.22 ; เหรือะ\n",
    "rule_l0_22 = r'(เห{}ื{}อะ)'.format(consonanth, toneq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - Level 1 cluster consonant may take additional final consonant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rule l1.1 ; ??? ค้า:15|เสรียั:l1_1|ง:d5| X followed by starter\n",
    "rule_l1_1 = r'(เ{}[รลว]ี?{}ย){}'.format(consonantc, toneq,startchar)\n",
    "\n",
    "# Rule l1.2 ; เหลี่ย|ม\n",
    "rule_l1_2 = r'(เห{}ี?{}ย)'.format(consonanth, toneq)\n",
    "\n",
    "# Rule l1.3 ; เคลือ เครอ\n",
    "rule_l1_3 = r'(เ{}[รลว]ื?{}อ)'.format(consonantc, toneq)\n",
    "\n",
    "# Rule l1.4 ; เหลือ\n",
    "rule_l1_4 = r'(เห{}ื{}อ)'.format(consonanth, toneq)\n",
    "\n",
    "# Rule l1.5 ; ???? มา|กว่า\n",
    "rule_l1_5 = r'({}[รลว]{}า)'.format(consonantc,toneq)\n",
    "\n",
    "# Rule l1.6 ; หนา, หน้า\n",
    "rule_l1_6 = '(ห{}{}า)'.format(consonanth,toneq)\n",
    "\n",
    "# Rule l1.7 ; ???? คลูก\n",
    "rule_l1_7 = '({}[รลว][ิีุู]{})'.format(consonantc,toneq)\n",
    "\n",
    "# Rule l1.8 ; หลี|อ\n",
    "rule_l1_8 = '(ห{}[ิี]{})'.format(consonanth, toneq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - Level 2 never take any more final consonant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rule 1 ; กัน\n",
    "rule_1 = '({}ั{}{})'.format(consonant,toneq,fconsonant)\n",
    "\n",
    "# Rule 1.1 ; ก็\n",
    "rule_1_1 = '({}็)'.format(consonant)\n",
    "\n",
    "# Rule 1.2 ; กำ น่ะ\n",
    "rule_1_2 = '({}{}[ะำ])'.format(consonant, toneq)\n",
    "\n",
    "# Rule 2 ; กั๊วะ\n",
    "rule_2 = '({}ั{}วะ)'.format(consonant, toneq)\n",
    "\n",
    "# Rule 3 ; เห็น\n",
    "rule_3 = '([เแ]{}็{})'.format(consonant, fconsonant)\n",
    "\n",
    "# Rule 4 ; โฮ๋ะ\n",
    "rule_4 = '([เแโ]{}{}ะ)'.format(consonant, toneq)\n",
    "\n",
    "# Rule 5 ; เงาะ\n",
    "rule_5 = '(เ{}{}าะ)'.format(consonant, toneq)\n",
    "\n",
    "# Rule 6 ; เงา\n",
    "rule_6 = '(เ{}{}า)'.format(consonant, toneq)\n",
    "\n",
    "# Rule 7 ; เงอะ\n",
    "rule_7 = '(เ{}{}อะ)'.format(consonant, toneq)\n",
    "\n",
    "# Rule 8 ; เงิก\n",
    "rule_8 = '(เ{}ิ{}{})'.format(consonant, toneq, fconsonant)\n",
    "\n",
    "# Rule 9 ; เงียะ\n",
    "rule_9 = '(เ{}ี{}ยะ)'.format(consonant, toneq)\n",
    "\n",
    "# Rule 10 ; เงือะ \n",
    "rule_10 =  '(เ{}ื{}อะ)'.format(consonant, toneq)\n",
    "\n",
    "# Rule 11 ; หวย ??? ค|ล่|อ|ง|แค|ล่วดี|\n",
    "rule_11 = '({}{}ว{}){}'.format(consonant, toneq, fconsonant,startchar)\n",
    "\n",
    "# Rule 12 ; กฤศ ??? ล|ดฤท|ธิ์|\n",
    "rule_12 = '({}ฤ{})'.format(consonant, fconsonant)\n",
    "\n",
    "# Rule 12.1 ; ให้\n",
    "rule_12_1 = '(ใ{}{})'.format(consonant, toneq)\n",
    "\n",
    "# Rule 16.1 ; หืม\n",
    "rule_16_1 = '({}[ื]{}{})'.format(consonant, toneq, fconsonant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - Level 3 may take additional final consonant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rule 13 ; เมีย\n",
    "rule_13 = '(เ{}ี{}ย)'.format(consonant, toneq)\n",
    "\n",
    "# Rule 14 ; เสือ, เออ\n",
    "rule_14 = '(เ{}ื{}อ){}'.format(consonant, toneq, startchar)\n",
    "\n",
    "# Rule 14e ; เสือ\n",
    "rule_14e = '(เ{}ื{}อ)'.format(consonant, toneq)\n",
    "\n",
    "# Rule 15 ; ง่า\n",
    "rule_15 = '({}{}า)'.format(consonant, toneq)\n",
    "\n",
    "# Rule 16 ; งี่ งิ งุ งู\n",
    "rule_16 = '({}[ิีุู]{})'.format(consonant, toneq)\n",
    "\n",
    "# Rule 17 ; แง่\n",
    "rule_17 = '([เแไโ]{}{})'.format(consonant, toneq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - Ad hoc rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rule a1 ; อย่า ??? ห่|อยา|\n",
    "rule_a1 = '(อย{}า)'.format(toneq)\n",
    "\n",
    "# Rule a2 ; อยู่ ??? ข้|อยุ|ติ\n",
    "rule_a2 = '(อย[ูุ]{})'.format(toneq)\n",
    "\n",
    "# Rule a3 ; หล่น\n",
    "rule_a3 = '(ห{}{}{})'.format(consonanth, tone, fkconsonant)\n",
    "\n",
    "# Rule a4 ; หน่วย\n",
    "rule_a4 = '(ห{}{}ว{})'.format(consonanth, tone, fconsonant)\n",
    "\n",
    "# Rule a5 ; ช่ง\n",
    "rule_a5 = '({}{}{})'.format(consonant, tone, fkconsonant)\n",
    "# Rule a6 ; อ้วน\n",
    "rule_a6 = '(อ{}ว{})'.format(tone, fkconsonant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All TCC rules. Please Comment out risky rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = {\n",
    "    'd1': rule_d1, # ฯลฯ\n",
    "    'd2': rule_d2, # Alphabet\n",
    "    'd3': rule_d3, # Number\n",
    "    'd4': rule_d4, # Attach ร์, ดิ์, ตร์, ทธิ์, ถุ์ to the existing previous unit\n",
    "    'd5': rule_d5, # Attach non-starting char to the existing previous unit\n",
    "    'l1_4': rule_l1_4,\n",
    "#    'l0_1': rule_l0_1, # ใคร, ใกล้ ???? สา|เกล้|น|แก้ว, โคล้|อมวง, ใหญ่:l0_2|โตร:l0_1|โห:17|ฐา:15|น:x|\n",
    "    'l0_2': rule_l0_2,  # ไหน, ไหล่\n",
    "#    'l0_3': rule_l0_3, # ครัว, ครั้ง ???? สิ|บวัน\n",
    "    'l0_4': rule_l0_4,  # หนัง, หยั่ง\n",
    "#    'l0_5': rule_l0_5, # คลำ, ประ, ??? แบ|บระ|บบ, แบ|บระ|ดับ\n",
    "    'l0_6': rule_l0_6,  # หนำ, หวะ\n",
    "    'l0_7': rule_l0_7,  # เสร็จ\n",
    "    'l0_8': rule_l0_8,  # เหม็น\n",
    "#    'l0_9': rule_l0_9, # แคระ, โคร่ะ ???? แประ|ยะ\n",
    "    'l0_10': rule_l0_10,\n",
    "    'l0_11': rule_l0_11,\n",
    "    'l0_12': rule_l0_12,\n",
    "#    'l0_13': rule_l0_13, # เคว้า, เขย่า ??? เทลา|ด\n",
    "    'l0_14': rule_l0_14,\n",
    "    'l0_15': rule_l0_15,\n",
    "    'l0_16': rule_l0_16,\n",
    "#    'l0_17': rule_l0_17, # เคล๋ ????\n",
    "#    'l0_18': rule_l0_18, # เหล๋ ????\n",
    "    'l0_19': rule_l0_19,\n",
    "    'l0_20': rule_l0_20,\n",
    "    'l0_20': rule_l0_20,\n",
    "    'l0_21': rule_l0_21,\n",
    "    'l0_22': rule_l0_22,\n",
    "    \n",
    "    'l1_1': rule_l1_1, # ??? ค้า:15|เสรียั:l1_1|ง:d5| X\n",
    "    'l1_2': rule_l1_2,\n",
    "#    'l1_3': rule_l1_3,\n",
    "\n",
    "#    'l1_5': rule_l1_5,\n",
    "    'l1_6': rule_l1_6,\n",
    "#    'l1_7': rule_l1_7,\n",
    "    'l1_8': rule_l1_8,\n",
    "    \n",
    "    '1': rule_1,\n",
    "#    '1_1': rule_1_1, # เพล่่ยั|ง\n",
    "    '1_2': rule_1_2,\n",
    "    '2': rule_2,\n",
    "    '3': rule_3,\n",
    "    '4': rule_4,\n",
    "    '5': rule_5,\n",
    "    '6': rule_6,\n",
    "#    '7': rule_7, # เทอะ|ไร\n",
    "    '8': rule_8,\n",
    "    '9': rule_9,\n",
    "    '10': rule_10,\n",
    "#    '11': rule_11, # ค|ล่|อ|ง|แค|ล่วดี|\n",
    "#    '12': rule_12, # ??? ล|ดฤท|ธิ์|\n",
    "    '12_1': rule_12_1,\n",
    "    '16_1': rule_16_1,\n",
    "    \n",
    "    '13': rule_13,\n",
    "    '14': rule_14,\n",
    "    '14e': rule_14e,\n",
    "    '15': rule_15,\n",
    "    '16': rule_16,\n",
    "    '17': rule_17,\n",
    "    \n",
    "#    'a1': rule_a1, # ห่|อยา|\n",
    "#    'a2': rule_a2, # อยู่ ??? ข้|อยุ|ติ\n",
    "    'a3': rule_a3,\n",
    "    'a4': rule_a4,\n",
    "#    'a5': rule_a5,\n",
    "    'a6': rule_a6\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thai Character Cluster Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tcc_segment(field, debug=False):\n",
    "    '''Apply Thai Character Cluster segmentation to field'''\n",
    "    output = []\n",
    "    rule_list = []\n",
    "    rlength = 1\n",
    "    i = 0\n",
    "    while i < len(field):\n",
    "        for rid in rules:\n",
    "            sub_field = field[i:]\n",
    "            match = re.match(rules[rid], sub_field)\n",
    "            if match:\n",
    "                rule_list.append(rid)\n",
    "                output.append(match.group(1))\n",
    "                rlength = len(match.group(1))\n",
    "                break\n",
    "        if not match:\n",
    "            rlength = 1\n",
    "            rule_list.append(\"x\")\n",
    "            output.append(sub_field[0])\n",
    "        i += rlength\n",
    "        \n",
    "    # join rule d5\n",
    "    if len(output) <= 0:\n",
    "        return []\n",
    "    temp_output = [output[0]]\n",
    "    for i in range(1, len(rule_list)):\n",
    "        if rule_list[i] == \"d5\":\n",
    "            temp_output[-1] += output[i]\n",
    "        else:\n",
    "            temp_output.append(output[i])\n",
    "    output = temp_output\n",
    "    if debug:\n",
    "        print(\"input: \" ,field)\n",
    "        print(\"Output: \", end = \" \")\n",
    "        for i, o in enumerate(output):\n",
    "            print('{}:{}|'.format(o,rule_list[i]), end=\"\")\n",
    "    #print(\"|\".join(output))\n",
    "    #print(\"|\".join(rule_list))\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = 0\n",
    "# encyclopedia article news novel\n",
    "folder = 'novel'\n",
    "dataset = os.listdir(folder)\n",
    "character_count = 0\n",
    "cluster_count = 0\n",
    "\n",
    "for data in dataset:\n",
    "    sentences = []\n",
    "    targets = []\n",
    "    with codecs.open(os.path.join(folder, data), 'r', encoding='UTF-8') as file:\n",
    "        for line in file:\n",
    "            line = line.replace(\"\\n\",\"\")\n",
    "            sentences.append(line.replace(\"|\",\"\"))\n",
    "            targets.append(line.split(\"|\"))\n",
    "\n",
    "    for ln, line in enumerate(sentences):\n",
    "        i = 0 \n",
    "        output = tcc_segment(sentences[ln])\n",
    "#         try:\n",
    "        for wid, target in enumerate(targets[ln]):\n",
    "            combine = \"\"\n",
    "            combine_debug = \"\"\n",
    "            character_count += len(target)\n",
    "            while len(target) > len(combine):\n",
    "                combine += output[i]\n",
    "                combine_debug += (output[i] + \"|\")\n",
    "                cluster_count += 1\n",
    "                i += 1\n",
    "            if target != combine:\n",
    "                if len(re.findall('{}+|{}+'.format(alphabet,number),target)) == 0:\n",
    "                    print()\n",
    "                    print(targets[ln][wid-1] + target + targets[ln][wid+1])\n",
    "                    print(\"T->\", target,\"P->\",combine_debug, flush=True)\n",
    "                error += 1\n",
    "                \n",
    "                #print(data)\n",
    "                break\n",
    "#         except:\n",
    "#             print('error')\n",
    "#             continue\n",
    "    print(\".\", end=\"\")\n",
    "print('character count= {}'.format(character_count))\n",
    "print('cluster count= {}'.format(cluster_count))\n",
    "print('reduced ratio= {}'.format(cluster_count/character_count))\n",
    "print('incorrect= {}'.format(error))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
